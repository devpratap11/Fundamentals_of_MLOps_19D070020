Ans1) AIOps(Artificial Intelligence for IT operations) might sound similar to MLOps but they have a subtle difference between them. AIOps is the application of AI to enhance IT operations. AIOps collects huge volumes of data generated by various tools in the corporation and filters out the signal from the noise in order to identify the pattern in data related to system performance.

To achieve this, AIOps makes use of a mix of analytics and machine learning concepts. Substituting multiple operation based tools with a single automated system is the purpose of AIOps and thus it enables the operation team to respond spontaneously to any anomalies and hazards without significant human intervention. AIOps forms the link between the ever-growing technology sphere and the consumer’s desire to receive top class application performance and uninterrupted availability.

MLOps and AIOps share the common goal, to provide the highest efficiency available to the consumers and make their lives easier, but they are quite different in their approaches. MLOps acts as the bridge between the data scientists and the operation team, which helps in the execution of the built ML model. AIOps, on the other hand, focuses more on making the available technology easily available to the consumer without any substantial human intervention in overcoming the hazards. AIOps focuses more on the delivery of the end product whereas the MLOps works on reinforcing the available technology.

Source: https://newrelic.com/blog/best-practices/how-does-aiops-work

Ans2) Interpretability is the degree to which a human can consistently predict the model's output. This statement is best highlighted by the fact that a more interpretable model would be easier to understand and a human could easily fathom the choices made by the model. A less interpretable model might be counterintuitive and thus it would be hard for a human to rightfully predict the outcome and understand the choices made by it. An interpretable model helps us to understand and account for the factors that aren’t included in the model and account for the context of the problem when taking actions based on model predictions. High interpretability usually leads to a model that generalises better.

Linear regression is one of the simplest machine learning techniques. Given and scatter plot of various data points, a human might as well easily figure out a general best-fit line(though not with 100% accuracy), which would highly resemble the actual output of the ML model. Alternatively, with a given output, a human may easily deduce the reason behind the particular fit and acknowledge the decision-making skills of the trained model.

Source: https://christophm.github.io/interpretable-ml-book/interpretability.html
